# mock_alerts.py

# This is the complete historical alert data, reconstructed from the full Slack log.
MOCK_ALERTS_HISTORY = [
    # June 30, 2025
    {
        "alertname": "VLLMHighAverageInferenceTime",
        "severity": "warning",
        "alertstate": "firing",
        "timestamp": "2025-06-30T14:54:40+00:00",
        "is_firing": 1,
        "labels": {
            "__name__": "ALERTS",
            "alertname": "VLLMHighAverageInferenceTime",
            "alertstate": "firing",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "namespace": "m2",
            "pod": "llama-3-2-3b-instruct-predictor-597d7d895f-mfgcv",
            "severity": "warning",
            "service": "kserve-container",
        },
    },
    {
        "alertname": "VLLMHighP95Latency",
        "severity": "critical",
        "alertstate": "firing",
        "timestamp": "2025-06-30T16:50:36+00:00",
        "is_firing": 1,
        "labels": {
            "__name__": "ALERTS",
            "alertname": "VLLMHighP95Latency",
            "alertstate": "firing",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "namespace": "linoy-metrics-summarizer-report",
            "pod": "llama-3-2-3b-instruct-predictor-58fcc6b96f-wf7x4",
            "severity": "critical",
            "service": "llama-3-2-3b-instruct-metrics",
        },
    },
    {
        "alertname": "VLLMHighAverageInferenceTime",
        "severity": "warning",
        "alertstate": "firing",
        "timestamp": "2025-06-30T16:50:36+00:00",
        "is_firing": 1,
        "labels": {
            "__name__": "ALERTS",
            "alertname": "VLLMHighAverageInferenceTime",
            "alertstate": "firing",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "namespace": "linoy-metrics-summarizer-report",
            "pod": "llama-3-2-3b-instruct-predictor-58fcc6b96f-wf7x4",
            "severity": "warning",
            "service": "llama-3-2-3b-instruct-metrics",
        },
    },
    {
        "alertname": "VLLMHighAverageInferenceTime",
        "severity": "warning",
        "alertstate": "firing",
        "timestamp": "2025-06-30T17:58:21+00:00",
        "is_firing": 1,
        "labels": {
            "__name__": "ALERTS",
            "alertname": "VLLMHighAverageInferenceTime",
            "alertstate": "firing",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "namespace": "peter-alerts",
            "pod": "llama-3-2-3b-instruct-predictor-5856469877-5knwx",
            "severity": "warning",
            "service": "llama-3-2-3b-instruct-metrics",
        },
    },
    {
        "alertname": "VLLMHighAverageInferenceTime",
        "severity": "warning",
        "alertstate": "firing",
        "timestamp": "2025-06-30T19:24:06+00:00",
        "is_firing": 1,
        "labels": {
            "__name__": "ALERTS",
            "alertname": "VLLMHighAverageInferenceTime",
            "alertstate": "firing",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "namespace": "m2",
            "pod": "llama-3-2-3b-instruct-predictor-597d7d895f-mfgcv",
            "severity": "warning",
            "service": "llama-3-2-3b-instruct-metrics",
        },
    },
    {
        "alertname": "VLLMHighP95Latency",
        "severity": "critical",
        "alertstate": "firing",
        "timestamp": "2025-07-13T19:38:06+00:00",
        "is_firing": 1,
        "labels": {
            "__name__": "ALERTS",
            "alertname": "VLLMHighP95Latency",
            "alertstate": "firing",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "namespace": "m2",
            "pod": "llama-3-2-3b-instruct-predictor-597d7d895f-mfgcv",
            "severity": "critical",
            "service": "llama-3-2-3b-instruct-metrics",
            "instance": "10.131.1.209:8080",
        },
    },
    {
        "alertname": "VLLMHighAverageInferenceTime",
        "severity": "warning",
        "alertstate": "firing",
        "timestamp": "2025-07-13T19:38:06+00:00",
        "is_firing": 1,
        "labels": {
            "__name__": "ALERTS",
            "alertname": "VLLMHighAverageInferenceTime",
            "alertstate": "firing",
            "model_name": "meta-llama/Llama-3.2-3B-Instruct",
            "namespace": "m2",
            "pod": "llama-3-2-3b-instruct-predictor-597d7d895f-mfgcv",
            "severity": "warning",
            "service": "llama-3-2-3b-instruct-metrics",
        },
    },
    # ... (and so on for all other alerts)
]
